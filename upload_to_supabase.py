import os
import csv
from supabase import create_client, Client

# --- Configuration ---
SUPABASE_URL = "https://wndnznopltyrbiujyhgh.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InduZG56bm9wbHR5cmJpdWp5aGdoIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2ODg3NzE1OCwiZXhwIjoyMDg0NDUzMTU4fQ.i8GtCqey7PW8q21E3Mw1fQKxYPmGIfQBOZr1HGGbu48"
TABLE_NAME = "bnm_notices"
CSV_FILE = "bnm_notices_partial.csv" # Using partial as scraper might have crashed

def upload_data():
    if not os.path.exists(CSV_FILE):
        print(f"Error: {CSV_FILE} not found.")
        return

    print("Connecting to Supabase...")
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    print(f"Reading from {CSV_FILE}...")
    records = []
    with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # Prepare record
            # Ensure column names match your Supabase table
            record = {
                "title": row.get("title"),
                "url": row.get("url"),
                "date": row.get("date"),
                "content": row.get("content") # Markdown content
            }
            records.append(record)
            
    if not records:
        print("No records found in CSV.")
        return

    print(f"Found {len(records)} records. Uploading to table '{TABLE_NAME}'...")
    
    # Upload in chunks to avoid timeouts
    CHUNK_SIZE = 100
    for i in range(0, len(records), CHUNK_SIZE):
        chunk = records[i:i + CHUNK_SIZE]
        print(f"Uploading batch {i//CHUNK_SIZE + 1} ({len(chunk)} items)...")
        
        try:
            # Using upsert based on URL if it's a unique key, or just insert
            # Note: For upsert to work, 'url' (or another col) must be a UNIQUE constraint in Postgres
            response = supabase.table(TABLE_NAME).upsert(chunk, on_conflict="url").execute()
            # print(response)
        except Exception as e:
            print(f"Error uploading batch: {e}")
            print("Make sure the table exists and columns match!")
            print(f"SQL to create table:\n")
            print(f"""
create table {TABLE_NAME} (
  id bigint generated by default as identity primary key,
  url text unique not null,
  title text,
  date text,
  content text,
  created_at timestamp with time zone default timezone('utc'::text, now()) not null
);
            """)
            break

    print("Upload process finished.")

if __name__ == "__main__":
    upload_data()
